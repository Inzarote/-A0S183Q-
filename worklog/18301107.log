个人工作日志
6.29 day 1
进行了环境的安装，配置spark时出现若干问题。初次安装使用3.0.0版本，但是hadoop难以找到对应版本的支持文件，所以安装后出现大量warning和一个exception。
看起来有问题，所以尝试安装2.4.6版本。获取到对应的支持文件后cmd测试无异常，似乎完成了任务五的要求。但是个人用pycharm测试时出现大量报错，无法运行。
搜索后发现是java版本不对，遂更换jdk1.8。安装后pycharm运行出现乱码，再次更新pycharm，成功运行输出结果。
6.30 day 2
上午帮助组内其他成员进行spark 安装，并完成任务6数据集的下载和任务7 安装数据分析相关的依赖包。正在进行任务8虚拟机安装相关。